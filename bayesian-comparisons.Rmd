Bayesian Matrix Comparisons following Aguirre et al.
========================================================

Samples
-------

Bayesian analysis rests upon having a posteriory distribution of the
parameters being estimated. In our case, these are the phenotipic
covariance matrices. When there were fixed effects, we obtain these
distributions by fiting th same multivariate linear models described
in the text using the package MCMCglmm, and when no fixed effects were
present we sampled from a Wishart distribution around the maximum
likelihood matrix. This procedure suplies a random sample of matrices
from each population's posterior distribution, that can then be used
to take into account uncertainty in the estimation in the comparisons
of the covariance structure of each population. Aguirre et al. (2013)
describe several methods for the comparison of covariance matrices
under this paradigm. Here, we show the Bayesian Random Skewers and the
Bayesian Krzanowski subspace methods.

Bayesian Random Skewers
-----------------------

From Aguirre et al. (2013):

    Each random vector (typically 1000 or more) is projected through each
    MCMC sample of each G-matrix to generate a posterior distribution of the
    genetic variance in the direction of the random vector for each population.
    Differences in genetic variance among populations are then evaluated by
    examining the overlap of the highest posterior density (HPD) intervals
    between all possible combinations of populations. All vectors that result in
    non-overlapping HPD intervals between any pair of populations are then
    collated, and the product-moment G of the vector elements calculated. This
    $n x n$ matrix (where n is the number of traits), R, describes which parts of the
    phenotypic space tend to show significant differences in genetic variance and
    this part of the space can be further investigated through an eigenanalysis of R.
    It is important to note that, because the random skewers probe the entire
    phenotypic space, each significant random skewer (that is, the vectors
    contributing to the estimation of R) can contain some component of those
    dimensions that significantly differ, as well as of those that do not. Therefore,
    to identify which dimensions of R represent genuine differences in genetic
    variance, we projected the eigenvectors of R back onto both the observed and
    randomised G-matrices.


```{r fig.width=15}
library(reshape2)
source('./b_random_skewers.R')

load('rs.proj.Rdata')

load('./xenartraMCMC.25.samples.Rdata')
#MCMC.R.proj.25 = R.proj(Ps)
rs.plots.25 = PlotBayesianRS(MCMC.R.proj.25, Ps)

load('./xenartraMCMC.28.samples.Rdata')
#MCMC.R.proj.28 = R.proj(Ps)
rs.plots.28 = PlotBayesianRS(MCMC.R.proj.28, Ps, 4)

load('./xenartraMCMC.32.samples.Rdata')
#MCMC.R.proj.32 = R.proj(Ps)
rs.plots.32 = PlotBayesianRS(MCMC.R.proj.32, Ps, 4)

load('./xenartraMCMC.35.samples.Rdata')
#MCMC.R.proj.35 = R.proj(Ps)
rs.plots.35 = PlotBayesianRS(MCMC.R.proj.35, Ps)

rs.plots = list('25' = rs.plots.25,
                '28' = rs.plots.28,
                '32' = rs.plots.32,
                '35' = rs.plots.35)
rs.plots[1:4]
```


Krzanowski shared space
-----------------------


```{r}
source('./KrzSubspace.R')
library(Morphometrics)

KrzMCMC = function(Ps, sample.size) {
    m = dim(Ps)[3]
    n = dim(Ps)[1]
    SamplePop = function(pop_Ps, n.ind, otu){
        pop = adply(pop_Ps, 3, function(x) mvtnorm::rmvnorm(n = n.ind,
                                                            mean = rep(0, dim(x)[2]),
                                                            sigma = x))
        pop$'.id' = otu
        return(pop)
    }
    pop_Ps = ldply(dimnames(Ps)[[3]], function(otu) SamplePop(Ps[,,which(dimnames(Ps)[[3]]==otu),],
                                                              sample.size[which(dimnames(Ps)[[3]]==otu)],
                                                              otu))
    shuffle = sample(dim(pop_Ps)[1])
    pop_Ps$'.id' = pop_Ps$'.id'[shuffle]
    pop_Ps$'X1' = pop_Ps$'X1'[shuffle]
    rand.Ps = daply(pop_Ps, .(X1, .id), function(x) cov(x[-c(1, dim(x)[2])]))
    rand.Ps = aperm(rand.Ps, c(3, 4, 2, 1))
    # We then calculate the shared subspace for the observed and random samples.
    MCMCG.kr.xenartra <- kr.subspace(Ps, vec = rep(n/2, m))
    MCMCG.kr.rand <- kr.subspace(rand.Ps, vec = rep(n/2, m))
    return(list(obs = MCMCG.kr.xenartra,
                rand = MCMCG.kr.rand))
}

load('./maindata.RData')
sample.size = ldply(x, function(x) as.data.frame(x$df))

MCMC.kr = list()

load('./xenartraMCMC.25.samples.Rdata')
MCMC.kr[['25']] = KrzMCMC(Ps, sample.size$D25)

load('./xenartraMCMC.28.samples.Rdata')
MCMC.kr[['28']] = KrzMCMC(Ps, sample.size$D28)

load('./xenartraMCMC.32.samples.Rdata')
MCMC.kr[['32']] = KrzMCMC(Ps, sample.size$D32)

load('./xenartraMCMC.35.samples.Rdata')
MCMC.kr[['35']] = KrzMCMC(Ps, sample.size$D35)

dat.krz = ldply(names(MCMC.kr),
                function(x) KrzSubspaceDataFrame (MCMC.kr[[x]][[1]],
                                                  MCMC.kr[[x]][[2]],
                                                  as.numeric(x)))

krz.plot = PlotKrzSubspace(dat.krz)
print(krz.plot)
```
